{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ac1236-9447-4e9d-a74b-d50dc36db9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from hmmlearn import hmm\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "np.set_printoptions(linewidth=300, suppress=True)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "from src.experiments.util_experiments import *\n",
    "from src.oom import DiscreteValuedOOM, ContinuousValuedOOM\n",
    "from src.oom.discrete_observable import DiscreteObservable\n",
    "from src.oom.util.few_step_prediction import quantify_distribution, kl_divergence, fix_pvec\n",
    "from src.oom.util.random_sparse import _generate_sparse_full_rank_matrix, _generate_observable_compound\n",
    "from src.oom.util.learning_discrete import estimate_matrices_discrete_fixed\n",
    "from src.oom.util.learning_continuous import estimate_matrices_continuous\n",
    "from src.oom.util.numrank import numerical_rank_binomial, numerical_rank_frob_mid_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa66b27-b1a0-4075-84f8-be380f8f90a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del sys.modules['src.oom.util.learning_discrete']\n",
    "# del sys.modules['src']\n",
    "# \n",
    "# del sys.modules['src.oom.util.numrank']\n",
    "# del numerical_rank_binomial\n",
    "# del numerical_rank_frob_mid_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce60d5f-8f8b-4e93-9586-ed65c4bdc10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dvoom_from_hmm(hmm_to_convert):\n",
    "    d = hmm_to_convert.n_components # dimension\n",
    "    n = hmm_to_convert.n_features   # observables\n",
    "    \n",
    "    lf = np.asmatrix(np.ones(shape=(1, d)))\n",
    "    ss = np.asmatrix(hmm_to_convert.get_stationary_distribution()).T\n",
    "\n",
    "    M = hmm_to_convert.transmat_\n",
    "    E = hmm_to_convert.emissionprob_\n",
    "    obs = [str(i+1) for i in range(n)]\n",
    "    ops = [np.matrix(M).T * np.asmatrix(np.diag(E[:, col])) for col in range(n)]\n",
    "    \n",
    "    return DiscreteValuedOOM(\n",
    "        dim               = d,\n",
    "        linear_functional = lf,\n",
    "        start_state       = ss,\n",
    "        obs_ops           = dict(zip(obs, ops))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e58a7-3e26-4d71-96dd-9adab6d9c680",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Assess pre-existing HMM creations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd13317-47ae-4b66-ad67-927b17b64147",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# (1) Create a random discrete-time HMM with 3 hidden states and 3 possible outputs\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Define parameters\n",
    "n_states = 4\n",
    "n_observations = 3\n",
    "\n",
    "# Random transition matrix (rows = current state, columns = next state)\n",
    "transmat = np.random.dirichlet(np.ones(n_states), size=n_states)\n",
    "transmat /= transmat.sum(axis=1, keepdims=True)  # Ensure row-stochastic\n",
    "\n",
    "# Random emission probabilities (rows = states, columns = observations)\n",
    "emission_probs = np.random.dirichlet(np.ones(n_observations), size=n_states)\n",
    "\n",
    "# Create the true HMM model\n",
    "true_model = hmm.CategoricalHMM(n_components=n_states)\n",
    "true_model.startprob_ = np.array([1.0, 0.0, 0.0, 0.0])  # Start in state 0\n",
    "true_model.transmat_ = transmat\n",
    "true_model.emissionprob_ = emission_probs\n",
    "true_model.startprob_ = true_model.get_stationary_distribution()\n",
    "\n",
    "true_model.emissionprob_\n",
    "# # (2) Generate training and test sequences\n",
    "# train_seq, train_states = true_model.sample(100000)\n",
    "# test_seq, test_states = true_model.sample(100000)\n",
    "\n",
    "# # (3) Compute NLL of the test sequence under the true model\n",
    "# true_nll = -true_model.score(test_seq) / test_seq.shape[0]\n",
    "# print(f\"True Model NLL on Test Sequence: {true_nll:.8f}\")\n",
    "\n",
    "# # (4) Train a new HMM on the training sequence\n",
    "# learned_model = hmm.CategoricalHMM(n_components=n_states, n_iter=100)\n",
    "# learned_model.fit(train_seq)\n",
    "\n",
    "# # (5) Compute NLL of the learned model on the test sequence\n",
    "# learned_nll = -learned_model.score(test_seq) / test_seq.shape[0]\n",
    "# print(f\"Learned Model NLL on Test Sequence: {learned_nll:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5531899-625d-4d90-aecc-8a5f246e990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 2\n",
    "# n = 2\n",
    "# d = 2\n",
    "# density = 0.8\n",
    "\n",
    "oom_model = make_source(name='S_3', case='discrete')\n",
    "n = len(oom_model.observables)\n",
    "d = oom_model.dim\n",
    "density = 0.4\n",
    "seed = 44 # for S_3\n",
    "\n",
    "rng = np.random.default_rng(seed = seed)\n",
    "rvs = sp.stats.uniform(loc = 0.01, scale = 1).rvs\n",
    "mu = _generate_sparse_full_rank_matrix(dim = d, sparsity = 1-density, rng = rng, rvs = rvs)\n",
    "Os = _generate_observable_compound(nrows = n, ncols = d, sparsity = 1-density, rng = rng, rvs = rvs)\n",
    "hmm_model = hmm.CategoricalHMM(n_components = d)\n",
    "hmm_model.startprob_ = np.zeros(shape = (d, 1))\n",
    "hmm_model.startprob_[0] = 1\n",
    "hmm_model.transmat_ = mu\n",
    "hmm_model.emissionprob_ = Os.T\n",
    "hmm_model.startprob_ = np.asarray(oom_model.start_state).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc9e6c-b412-4401-b021-10a4f94d388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f6cb7-1bc4-4fbf-8860-14b08bb28aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOM generation\n",
    "oom_gen_train = oom_model.generate(5000).sequence\n",
    "oom_nll_oom_gen_train = oom_model.compute(oom_gen_train).nll_list[-1]\n",
    "\n",
    "oom_gen_train_modforhmm = np.array([ord(obs.uid[1:])-ord('a') for obs in oom_gen_train]).reshape(-1, 1)\n",
    "hmm_nll_oom_gen_train = -hmm_model.score(oom_gen_train_modforhmm) / (oom_gen_train_modforhmm.shape[0] * np.log(2))\n",
    "\n",
    "# HMM generation\n",
    "hmm_gen_train, _ = hmm_model.sample(5000)\n",
    "hmm_nll_hmm_gen_train = -hmm_model.score(hmm_gen_train) / (hmm_gen_train.shape[0] * np.log(2))\n",
    "\n",
    "hmm_gen_train_modforoom = [DiscreteObservable( chr(i + ord('a')) ) for i in list(hmm_gen_train.flatten())]\n",
    "oom_nll_hmm_gen_train = oom_model.compute(hmm_gen_train_modforoom).nll_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c642b4b-792e-49c1-ba48-98ccdba9fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oom_nll_oom_gen_train, hmm_nll_oom_gen_train, hmm_nll_hmm_gen_train, oom_nll_hmm_gen_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69cd51-bee2-495a-8769-cf4a33cf6801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab68624-7d78-4163-a3e0-2554fc37fa7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bed16-32ad-48b8-9b98-20d1699de62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = oom_model.generate(10 ** 5)\n",
    "print(\"Done generating train_seq\")\n",
    "test_seqs = [oom_model.generate(5 * 10 ** 3) for _ in range(5)]\n",
    "print(\"Done generating test_seq\")\n",
    "\n",
    "oom_model_nlls = [oom_model.compute(test_seq.sequence).nll_list[-1] for test_seq in tqdm(test_seqs)]\n",
    "oom_model_mean_nll = np.mean(oom_model_nlls)\n",
    "oom_model_std_nll = np.std(oom_model_nlls)\n",
    "print(f\"True Model NLL on Test Sequence: {oom_model_mean_nll:.4f}+-{oom_model_std_nll:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5304e5f3-3b52-43cb-8e21-5ec6b5cdc74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsp5_source = fix_pvec(quantify_distribution(5, oom_model.start_state, oom_model.operators, oom_model.lin_func))\n",
    "train_seq_modforhmm = np.array([ord(obs.uid[1:])-ord('a') for obs in train_seq.sequence]).reshape(-1, 1)\n",
    "test_seqs_modforhmm = [\n",
    "    np.array([ord(obs.uid[1:])-ord('a') for obs in test_seq.sequence]).reshape(-1, 1)\n",
    "    for test_seq in test_seqs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777a804-49e0-4aea-939c-f40f12b7b4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada2638f-3567-4b4b-b571-b017b179f820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e14018-1bac-4acf-ae63-7a471a8c7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(divide='ignore')\n",
    "\n",
    "best_hmm, best_hmm_kl, best_hmm_nll = None, np.inf, np.inf\n",
    "best_oom, best_oom_kl, best_oom_nll = None, np.inf, np.inf\n",
    "\n",
    "for seqlength_spec in range(4, 10 + 1):#, 10**6, 10**7, 10**8]:\n",
    "    seqlength = int(10 ** (seqlength_spec/2))\n",
    "    len_cwords = 2\n",
    "    len_iwords = 3\n",
    "    \n",
    "    estimated_matrices = estimate_matrices_discrete_fixed(\n",
    "        sequence   = train_seq.sequence[:seqlength],\n",
    "        len_cwords = len_cwords,\n",
    "        len_iwords = len_iwords\n",
    "    )\n",
    "    # print(*estimated_matrices, sep='\\n')\n",
    "    rankmax = np.linalg.matrix_rank(estimated_matrices[0][0])\n",
    "    ranknum_fms, e_fms = numerical_rank_frob_mid_spec(estimated_matrices[0][0], seqlength, len_cwords, len_iwords, ret_bound=True)\n",
    "    ranknum_bin, svals_bin, e_bin = numerical_rank_binomial(estimated_matrices[0][0], seqlength)\n",
    "    print(f\"{rankmax=}, {ranknum_bin=} at {e_bin=:.5f}, {ranknum_fms=} at {e_fms=:.5f}\")#   {svals_bin[:5]=}\")\n",
    "    \n",
    "    d1_range = range(2, min(rankmax, ranknum_bin + 1, 10))\n",
    "    d1_range = range(max(ranknum_bin, 2), min(rankmax, max(ranknum_bin, 2) + 5))\n",
    "    d1_range = range(max(ranknum_fms, 2), min(rankmax, max(ranknum_fms, 2) + 5))\n",
    "    # d1_range = [2]\n",
    "    for d1 in d1_range:\n",
    "        # Estimate HMM\n",
    "        learned_hmm = hmm.CategoricalHMM(n_components = d1, n_iter = 16)\n",
    "        learned_hmm.fit(train_seq_modforhmm[:seqlength])\n",
    "        hmm_nlls = []\n",
    "        for test_seq_modforhmm in test_seqs_modforhmm:\n",
    "            learned_hmm_nll_test = -learned_hmm.score(test_seq_modforhmm) / (test_seq_modforhmm.shape[0] * np.log(2))\n",
    "            hmm_nlls.append(learned_hmm_nll_test)\n",
    "        hmm_mean_nll = np.mean(hmm_nlls)\n",
    "        hmm_std_nll = np.std(hmm_nlls)\n",
    "        \n",
    "        conv_hmm: DiscreteValuedOOM = dvoom_from_hmm(learned_hmm)\n",
    "        fsp5_hmm = fix_pvec(quantify_distribution(5, conv_hmm.start_state, conv_hmm.operators, conv_hmm.lin_func))\n",
    "        kldiv_hmm = kl_divergence(fsp5_source, fsp5_hmm)\n",
    "        \n",
    "        # if kldiv_hmm < best_hmm_kl: best_hmm, best_hmm_kl = conv_hmm, kldiv_hmm\n",
    "        if (learned_hmm_nll_test-oom_model_mean_nll) < (best_hmm_nll-oom_model_mean_nll):\n",
    "            best_hmm, best_hmm_kl, best_hmm_nll = conv_hmm, kldiv_hmm, learned_hmm_nll_test\n",
    "\n",
    "        # Estimate OOM\n",
    "        dvoom = DiscreteValuedOOM.from_data(\n",
    "            obs = train_seq.sequence[:seqlength],\n",
    "            target_dimension = d1,\n",
    "            len_cwords = len_cwords,\n",
    "            len_iwords = len_iwords,\n",
    "            estimated_matrices = estimated_matrices\n",
    "        )\n",
    "        dvoom.normalize(ones_row=True)\n",
    "        dvoom_nlls = [dvoom.compute(test_seq.sequence).nll_list[-1] for test_seq in test_seqs]\n",
    "        dvoom_mean_nll = np.mean(dvoom_nlls)\n",
    "        dvoom_std_nll = np.std(dvoom_nlls)\n",
    "\n",
    "        fsp5_oom = fix_pvec(quantify_distribution(5, dvoom.start_state, dvoom.operators, dvoom.lin_func))\n",
    "        kldiv_oom = kl_divergence(fsp5_source, fsp5_oom)\n",
    "        # if kldiv_oom < best_oom_kl: best_oom, best_oom_kl = dvoom, kldiv_oom\n",
    "        if abs(dvoom_mean_nll-oom_model_mean_nll) < (best_oom_nll-oom_model_mean_nll):\n",
    "            best_oom, best_oom_kl, best_oom_nll = dvoom, kldiv_oom, dvoom_mean_nll\n",
    "        # print(fsp5_oom)\n",
    "        \n",
    "        print(f\"Metrics for length {seqlength:>10}: \"\n",
    "              f\"HMM({d1=})  NLL = {hmm_mean_nll:.3f}+-{hmm_std_nll:.3f}   KL = {kldiv_hmm:.4f}      \"\n",
    "              f\"OOM({d1=})  NLL = {dvoom_mean_nll:.3f}+-{dvoom_std_nll:.3f}  KL = {kldiv_oom:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaea02d-03b4-441f-87e7-e6f272a52a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5c587-89cf-4011-bf2c-81a2c0951cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_oom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772192a-cd87-45a8-9398-65968b0d499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(p, q):\n",
    "    return np.mean((p - q) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d01798-ccfc-4010-99d4-b97826f172f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 5\n",
    "\n",
    "model_pvec = fix_pvec(quantify_distribution(q, oom_model.start_state, oom_model.operators, oom_model.lin_func))\n",
    "besth_pvec = fix_pvec(quantify_distribution(q, best_hmm.start_state, best_hmm.operators, best_hmm.lin_func))\n",
    "besto_pvec = fix_pvec(quantify_distribution(q, best_oom.start_state, best_oom.operators, best_oom.lin_func))\n",
    "\n",
    "plt.plot(model_pvec, label=\"source (ground truth)\")\n",
    "plt.plot(besth_pvec, label=\"best hmm approximator\")\n",
    "plt.plot(besto_pvec, label=\"best oom approximator\")\n",
    "plt.title(f\"Entries of the probability vectors for {q}-step predictive sequences\")\n",
    "plt.xticks(\n",
    "    labels=[oom_model.observables[0].uid[1:] * q, oom_model.observables[-1].uid[1:] * q],\n",
    "    ticks = [0, len(oom_model.observables)**q],\n",
    "    rotation = 20\n",
    ")\n",
    "\n",
    "# plt.ylim([0, 1])\n",
    "plt.xlim([0, len(oom_model.observables)**q])\n",
    "# plt.axhline(fix_pvec(quantify_distribution(q, oom_model.start_state, oom_model.operators, oom_model.lin_func))[0], ls='--')\n",
    "# plt.axhline(fix_pvec(quantify_distribution(q, oom_model.start_state, oom_model.operators, oom_model.lin_func))[1], ls='--')\n",
    "# plt.plot(fix_pvec(quantify_distribution(q, best_oom.start_state, best_oom.operators, best_oom.lin_func))[::-1], label=\"best oom reversed\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "print(\n",
    "    \"KL = %.5f, MSE = %.10f for best HMM\" % (kl_divergence(model_pvec, besth_pvec), mse(model_pvec, besth_pvec)),\n",
    "    \"KL = %.5f, MSE = %.10f for best OOM\" % (kl_divergence(model_pvec, besto_pvec), mse(model_pvec, besto_pvec)),\n",
    "    sep='\\n'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1784c396-1cfb-4263-9c8f-291845f84a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4760948c-48c9-4714-9338-736ebd86d0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acad69b-d54c-4594-a133-2fc45bafdf89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d644b-deb0-41ca-a895-fd110a1e01ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3b44d2-f70d-4406-a631-0601caf503c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75530ad6-c1e3-468f-90b2-bfea09358e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31057b-5396-4f2f-a2b9-b94337aed28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c53185-a9ff-4f48-84f9-300b1de743d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139906c1-abbf-4862-b54b-00c86edd0389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7ecd911-e78e-4ecc-a8b2-0a85891232ab",
   "metadata": {},
   "source": [
    "# Fundamental Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584f8a31-de55-4036-af28-54aa4c41e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True transition matrix:\n",
      " [[0.8 0.2]\n",
      " [0.2 0.8]]\n",
      "True emission matrix:\n",
      " [[0.9 0.1]\n",
      " [0.1 0.9]]\n",
      "First 10 observations: [1 0 1 0 0 0 1 1 1 1]\n",
      "First 10 hidden states: [1 1 1 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Create stationary transition matrix (symmetric for easy stationary distribution)\n",
    "transmat = np.array([[0.8, 0.2],  # From state 0: 80% stay, 20% to state 1\n",
    "                     [0.2, 0.8]]) # From state 1: 20% to state 0, 80% stay\n",
    "\n",
    "# Distinct emissions (easy to distinguish states)\n",
    "emissionprob = np.array([[0.9, 0.1],  # State 0: 90% 'a', 10% 'b\n",
    "                         [0.1, 0.9]]) # State 1: 10% 'a', 90% 'b'\n",
    "\n",
    "# Stationary distribution (eigenvector for eigenvalue 1)\n",
    "startprob = np.array([0.5, 0.5])  # Stationary for symmetric transitions\n",
    "\n",
    "# Create and configure model\n",
    "model = hmm.CategoricalHMM(n_components=2, implementation=\"log\")\n",
    "model.n_features = 2  # Number of observable symbols (a=0, b=1)\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.emissionprob_ = emissionprob\n",
    "\n",
    "# Generate test sequence\n",
    "observations, states = model.sample(1000)\n",
    "\n",
    "# Verify parameters\n",
    "print(\"True transition matrix:\\n\", transmat)\n",
    "print(\"True emission matrix:\\n\", emissionprob)\n",
    "print(\"First 10 observations:\", observations[:10].flatten())\n",
    "print(\"First 10 hidden states:\", states[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1939da1c-ab5a-4a0f-a9e4-4d3f6e0d41a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfs = [sp.stats.uniform(loc=0, scale=1), sp.stats.uniform(loc=1, scale=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1bc064b-0046-45c7-a122-866b935e9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_hmm_disc = dvoom_from_hmm(model)\n",
    "conv_hmm = ContinuousValuedOOM.from_discrete_valued_oom(\n",
    "    conv_hmm_disc,\n",
    "    mfs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e9596c3-28d8-41ea-b13c-552c8bc7aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chgen = conv_hmm.generate(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a72c901-4b90-492e-a2e7-6ff6e03e19f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[O1, O1, O1, O1, O2, O2, O2, O2, O2, O1] \n",
      " [0.403267692336974, 0.10416824731331464, 0.33005924751460936, 0.921766128710205, 1.6549606110411323, 1.4661528878609498, 1.0003806974222136, 1.4075985991606257, 1.3366024033463306, 0.0204982689493034]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 996/996 [00:00<00:00, 15122.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.0\n",
      "0 1 0.0\n",
      "1 0 0.0\n",
      "1 1 0.9999999999999084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0.17151454 0.03209629 0.06018054 0.05416249]\n",
      " [0.06118355 0.01705115 0.02607823 0.04513541]\n",
      " [0.03109328 0.02607823 0.01805416 0.07321966]\n",
      " [0.05616851 0.07321966 0.0441324  0.2106319 ]]\n",
      "\n",
      "O1\n",
      "[[0.12550201 0.02309237 0.04518072 0.03714859]\n",
      " [0.04618474 0.00903614 0.01506024 0.01706827]\n",
      " [0.02008032 0.00803213 0.01104418 0.01004016]\n",
      " [0.04116466 0.00903614 0.01506024 0.03514056]]\n",
      "\n",
      "O2\n",
      "[[0.01807229 0.01606426 0.01405622 0.03815261]\n",
      " [0.01305221 0.01004016 0.00401606 0.03514056]\n",
      " [0.01506024 0.02008032 0.01104418 0.05321285]\n",
      " [0.04016064 0.05321285 0.03313253 0.15763052]]\n",
      "\n",
      "[[0.31931932 0.14914915 0.14814815 0.38338338]]\n",
      "\n",
      "[[0.31931932]\n",
      " [0.14914915]\n",
      " [0.14814815]\n",
      " [0.38338338]]\n",
      "\n",
      "rank_bin: 2 [294.28475368 138.94300945   2.86112885   0.83058658] 56.87764511077113\n",
      "rank_fms: 2 0.024428881986806313\n",
      "rank_tru: 4\n",
      "\n",
      "\n",
      "\n",
      "**************************************************\n",
      "BEFORE NORMALIZATION\n",
      "**************************************************\n",
      "\n",
      "\n",
      "<ContinuousValuedOOM object with dimension 2 and alphabet size 2>\n",
      "functional = [[-1.8348185   0.24399875]]\n",
      "start state = [[-0.5402239  0.0360133]]^T\n",
      "alphabet = [O1, O2]\n",
      "    O1 operator matrix:\n",
      "[[ 0.4109767  -0.47870672]\n",
      " [-0.21243043  0.44623958]]\n",
      "    O2 operator matrix:\n",
      "[[0.58726936 0.43488943]\n",
      " [0.19924119 0.22426381]]\n",
      "\n",
      "\n",
      "<ContinuousValuedOOM object with dimension 2 and alphabet size 2>\n",
      "functional = [[1. 1.]]\n",
      "start state = [[0.5 0.5]]^T\n",
      "alphabet = [O1, O2]\n",
      "    O1 operator matrix:\n",
      "[[0.72 0.02]\n",
      " [0.18 0.08]]\n",
      "    O2 operator matrix:\n",
      "[[0.08 0.18]\n",
      " [0.02 0.72]]\n",
      "\n",
      "\n",
      "original model has NLL 0.8821015093109768 and learned has NLL 0.886038458553375\n",
      "\n",
      "\n",
      "**************************************************\n",
      "AFTER NORMALIZATION\n",
      "**************************************************\n",
      "\n",
      "\n",
      "<ContinuousValuedOOM object with dimension 2 and alphabet size 2>\n",
      "functional = [[1. 1.]]\n",
      "start state = [[0.9912128 0.0087872]]^T\n",
      "alphabet = [O1, O2]\n",
      "    O1 operator matrix:\n",
      "[[0.4109767  3.59977227]\n",
      " [0.02824953 0.44623958]]\n",
      "    O2 operator matrix:\n",
      "[[ 0.58726936 -3.27027566]\n",
      " [-0.02649559  0.22426381]]\n",
      "\n",
      "\n",
      "<ContinuousValuedOOM object with dimension 2 and alphabet size 2>\n",
      "functional = [[1. 1.]]\n",
      "start state = [[0.5 0.5]]^T\n",
      "alphabet = [O1, O2]\n",
      "    O1 operator matrix:\n",
      "[[0.72 0.02]\n",
      " [0.18 0.08]]\n",
      "    O2 operator matrix:\n",
      "[[0.08 0.18]\n",
      " [0.02 0.72]]\n",
      "\n",
      "\n",
      "original model has NLL 0.8821015093109768 and learned has NLL 0.8860384585533753\n"
     ]
    }
   ],
   "source": [
    "len_cwords = 2\n",
    "len_iwords = 2\n",
    "seqlen = 1000\n",
    "\n",
    "print(chgen.sequence[:10], '\\n', chgen.sequence_cont[:10], end='\\n\\n')\n",
    "\n",
    "estimated_matrices = estimate_matrices_continuous(\n",
    "    sequence   = chgen.sequence_cont[:seqlen],\n",
    "    len_cwords = len_cwords,\n",
    "    len_iwords = len_iwords,\n",
    "    membership_functions = conv_hmm.membership_fns,\n",
    "    observables = conv_hmm.observables\n",
    ")\n",
    "for item in estimated_matrices:\n",
    "    if isinstance(item, dict):\n",
    "        for key, val in item.items():\n",
    "            print(key, val, sep='\\n', end='\\n\\n')\n",
    "    else: print(item, end='\\n\\n')\n",
    "\n",
    "print(\"rank_bin:\", *numerical_rank_binomial(estimated_matrices[0][0], seqlen))\n",
    "print(\"rank_fms:\", *numerical_rank_frob_mid_spec(estimated_matrices[0][0], seqlen, len_cwords, len_iwords, ret_bound=True))\n",
    "print(\"rank_tru:\", np.linalg.matrix_rank(estimated_matrices[0][0]))\n",
    "print()\n",
    "\n",
    "learned = ContinuousValuedOOM.from_data(\n",
    "    chgen.sequence_cont[:seqlen],\n",
    "    target_dimension = 2,\n",
    "    len_cwords = len_cwords,\n",
    "    len_iwords = len_iwords,\n",
    "    observables = conv_hmm.observables,\n",
    "    membership_functions = conv_hmm.membership_fns,\n",
    "    estimated_matrices = estimated_matrices\n",
    ")\n",
    "\n",
    "q=1\n",
    "test_seq = conv_hmm.generate(50000)\n",
    "nll_conv_hmm = conv_hmm.compute(test_seq.sequence_cont).nll_list[-1]\n",
    "\n",
    "print('\\n\\n' + ('*' * 50) + '\\nBEFORE NORMALIZATION\\n' + ('*' * 50) + '\\n\\n')\n",
    "\n",
    "print(\n",
    "    learned,\n",
    "    conv_hmm,\n",
    "    # fix_pvec(quantify_distribution(q, learned.start_state, learned.operators, learned.lin_func)),\n",
    "    # fix_pvec(quantify_distribution(q, conv_hmm.start_state, conv_hmm.operators, conv_hmm.lin_func)),\n",
    "    # kl_divergence(\n",
    "    #     fix_pvec(quantify_distribution(q, learned.start_state, learned.operators, learned.lin_func)),\n",
    "    #     fix_pvec(quantify_distribution(q, conv_hmm.start_state, conv_hmm.operators, conv_hmm.lin_func))\n",
    "    # ),\n",
    "    # fix_pvec(quantify_distribution(5, learned.start_state, learned.operators, learned.lin_func)),\n",
    "    # fix_pvec(quantify_distribution(5, conv_hmm.start_state, conv_hmm.operators, conv_hmm.lin_func)),\n",
    "    # kl_divergence(\n",
    "    #     fix_pvec(quantify_distribution(5, learned.start_state, learned.operators, learned.lin_func)),\n",
    "    #     fix_pvec(quantify_distribution(5, conv_hmm.start_state, conv_hmm.operators, conv_hmm.lin_func))\n",
    "    # ),\n",
    "    f\"original model has NLL {nll_conv_hmm} and learned has NLL {learned.compute(test_seq.sequence_cont).nll_list[-1]}\",\n",
    "    sep='\\n\\n'\n",
    ")\n",
    "\n",
    "print('\\n\\n' + ('*' * 50) + '\\nAFTER NORMALIZATION\\n' + ('*' * 50) + '\\n\\n')\n",
    "\n",
    "learned.normalize(ones_row=True)\n",
    "print(\n",
    "    learned,\n",
    "    conv_hmm,\n",
    "    # fix_pvec(quantify_distribution(q, learned.start_state, learned.operators, learned.lin_func)),\n",
    "    # fix_pvec(quantify_distribution(q, conv_hmm.start_state, conv_hmm.operators, conv_hmm.lin_func)),\n",
    "    # kl_divergence(\n",
    "    #     fix_pvec(quantify_distribution(q, learned.start_state, learned.operators, learned.lin_func)),\n",
    "    #     fix_pvec(quantify_distribution(q, conv_hmm.start_state, conv_hmm.operators, conv_hmm.lin_func))\n",
    "    # ),\n",
    "    # fix_pvec(quantify_distribution(5, learned.start_state, learned.operators, learned.lin_func)),\n",
    "    # fix_pvec(quantify_distribution(5, conv_hmm.start_state, conv_hmm.operators, conv_hmm.lin_func)),\n",
    "    # kl_divergence(\n",
    "    #     fix_pvec(quantify_distribution(5, learned.start_state, learned.operators, learned.lin_func)),\n",
    "    #     fix_pvec(quantify_distribution(5, conv_hmm.start_state, conv_hmm.operators, conv_hmm.lin_func))\n",
    "    # ),\n",
    "    f\"original model has NLL {nll_conv_hmm} and learned has NLL {learned.compute(test_seq.sequence_cont).nll_list[-1]}\",\n",
    "    sep='\\n\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9df6586f-a19c-476b-8f45-c624c0c10e45",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,))\n\u001b[0;32m      2\u001b[0m d \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m----> 3\u001b[0m \u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "arr = np.ones(shape=(5,))\n",
    "d = arr.size\n",
    "arr[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "369e33d6-a839-47f3-98e1-3c492670804a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.88888889, 0.77777778, 0.66666667, 0.55555556, 0.44444444, 0.33333333, 0.22222222, 0.11111111, 0.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svals_simd = np.linspace(1, 0, 10)\n",
    "svals_simd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01942924-c48a-4501-9a28-34729c11d3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_num = svals_simd.size\n",
    "cutoff = 0\n",
    "rank_num, cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc99ea1-e335-44bc-ae3b-7f3978298a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while rank_num > 0 and s2_tailsum <= cutoff:\n",
    "    d_numrank -= 1\n",
    "    s2_tailsum += s[d_numrank]**2\n",
    "\n",
    "e = s[d_numrank] - (s2_tailsum**0.5 - e**0.5) / s[d_numrank] * (s[d_numrank] - (0 if d_numrank == len(s) else s[d_numrank+1]))\n",
    "d_numrank += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
